{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm3KgL2Q_H9S"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HBD94XG_LXL"
   },
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCai-GWb_V-q"
   },
   "source": [
    "Throughout the class, we've been looking at many ways to analyze and extract spatial information from images. Now we'll briefly talk about how we can extract the temporal information in a sequence of images.\n",
    "\n",
    "One way of getting temporal information is through optical flow, which is the apparent motion of brightness patterns in the image. Ideally, optical flow would be the same as the motion field, which is a representation of real world 3D motion. So by finding the optical flow field, we can hopefully observe real world motion behavior of objects that are present in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = 'data/taxi.gif'\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(open(vid_path, 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfFlltjAAkTN"
   },
   "source": [
    "We will use `cv2.VideoCapture()` to load the data in the gif file, retrive some properties of the sequence, and also convert it to a sequence of grayscale images.\n",
    "\n",
    "(2 points) Complete the cell below. You can refer to OpenCV's docs about the [`get()`](https://docs.opencv.org/4.6.0/d8/dfe/classcv_1_1VideoCapture.html#aa6480e6972ef4c00d74814ec841a2939) and [`read()`](https://docs.opencv.org/4.6.0/d8/dfe/classcv_1_1VideoCapture.html#a473055e77dd7faa4d26d686226b292c1) methods of the `VideoCapture` obeject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "NIBwdYfjSQNX",
    "outputId": "d3056106-b52e-419a-88ea-8ec859793141"
   },
   "outputs": [],
   "source": [
    "gif = cv2.VideoCapture(vid_path)\n",
    "\n",
    "num_frames = \n",
    "height = \n",
    "width = \n",
    "\n",
    "frames = []\n",
    "for i in range(num_frames):\n",
    "    # TODO\n",
    "    frames.append(frame_gray)\n",
    "\n",
    "plt.imshow(frames[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIvm4coYB_Ez"
   },
   "source": [
    "In the lecture, we saw that to calculate the optical flow, we assumed brightness contancy, small motion, and spatial coherence. This allows us to use gradients within a frame and between frames to determine motion of pixels from one frame to another.\n",
    "\n",
    "(3 points) Fill out the function below that takes two frames, computes the $\\sum I_xI_x$, $\\sum I_xI_y$, and $\\sum I_yI_y$ terms for the second frame, and the $\\sum I_xI_t$ and $\\sum I_yI_t$ terms between the two frames.\n",
    "\n",
    "For $I_x$ and $I_y$, use `np.gradient()` on the second frame, and $I_t$ should be the pixel-wise difference between the two frames. $I_xI_x$, $I_yI_y$, $I_xI_y$, $I_xI_t$, and $I_yI_t$ are computed with pixel wise multiplication as usual. To compute the sums, at every pixel sum up elements in a window weighted by Gaussian weights. To be specific, use `scipy.ndimage.gaussian_filter()` with `sigma=3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRJ1VChHFlLI"
   },
   "outputs": [],
   "source": [
    "def get_gradients(im1, im2):\n",
    "    \"\"\"Computes the gradients needed to find optical flow between im2 and im1.\n",
    "      \n",
    "      Args:\n",
    "      - im1: First frame of shape (height, width).\n",
    "      - im2: Second frame of shape (height, width).\n",
    "      Returns:\n",
    "      - i_xx_sum: Array of shape (height, width) where each element represents\n",
    "          the sum of  I_x I_x values in a Gaussian window around the pixel.\n",
    "      - i_xy_sum: ... I_x I_y ...\n",
    "      - i_yy_sum: ... I_y I_y ...\n",
    "      - i_xt_sum: ... I_x I_t ...\n",
    "      - i_yt_sum: ... I_y I_t ...\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    \n",
    "    return i_xx_sum, i_xy_sum, i_yy_sum, i_xt_sum, i_yt_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sR56E-mZI1iu"
   },
   "source": [
    "(1 point) Why do we sum the gradient terms in a window around each pixel? What assumption are we making here that allows us to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we assume spatial coherence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsldkzzbIMPv"
   },
   "source": [
    "(4 points) Using those gradients, we can create a least squares equation that is similar to the Harris Corner Detector. In the function below, fill out the missing lines to finish the function to find optical flow.\n",
    "\n",
    "Note that when solving for $[u, v]^T$, we don't use `np.linalg.lstsqr()` or other functions from an external library - we can solve for it directly, as from the slides we see $d=(A^TA)^{-1}(-A^Tb)$, and we check beforehand whether $A^TA$ is invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PwCSEpXQmKh"
   },
   "outputs": [],
   "source": [
    "def optical_flow(im1, im2, stride):\n",
    "    \"\"\"Computes the optical flow between frames im2 and im1.\n",
    "    Args:\n",
    "        im1: First frame of size [height, width].\n",
    "        im2: Second frame of size [height, width].\n",
    "        stride: Determines how dense you want the optical flow field to be.\n",
    "    Returns:\n",
    "        u: x value of optical flow vector of every pixel.\n",
    "        v: y value of optical flow vector of every pixel.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calls our previous function to get the image gradients.\n",
    "    height, width = im1.shape\n",
    "    i_xx_sum, i_xy_sum, i_yy_sum, i_xt_sum, i_yt_sum = \\\n",
    "        get_gradients(im1, im2)\n",
    "\n",
    "    # Create containers for storing the u, v components of optical flow\n",
    "    # vector for each pixel.\n",
    "    u = np.zeros(im1.shape)\n",
    "    v = np.zeros(im2.shape)\n",
    "\n",
    "    # Loop through every stride pixels\n",
    "    for i in range(0, height, stride):\n",
    "        for j in range(0, width, stride):\n",
    "            # Find the A^T @ A matrix for this pixel (see slides).\n",
    "            # TODO\n",
    "            \n",
    "            # Find the A^T @ b matrix for this pixel (see slides).\n",
    "            # TODO\n",
    "\n",
    "            # Compute the determinant of the A^T @ A matrix, and if it zero,\n",
    "            # we move on to the next pixel.\n",
    "            # TODO\n",
    "            if det == 0:\n",
    "                continue\n",
    "\n",
    "            # Directly solve for the u, v terms.\n",
    "            # TODO\n",
    "\n",
    "    return u, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx05-swpKqfO"
   },
   "source": [
    "We can now test it on the image sequence we extracted from the gif file. If it's taking too long, you can change the stride to be 2 instead of 1. (For me, it takes around 31 seconds with `stride=1`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VjFyA0TS44M"
   },
   "outputs": [],
   "source": [
    "us = []\n",
    "vs = []\n",
    "\n",
    "for i in tqdm(range(1, num_frames)):\n",
    "    u, v = optical_flow(frames[i-1], frames[i], 1)\n",
    "    us.append(u)\n",
    "    vs.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzYLiOKGL9-T"
   },
   "source": [
    "Let's visualize the optical flow field gradient. The cell below computes the magnitude of optical flow at every pixel for each frame and saves the result as a gif file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = np.sqrt(np.array(us)**2 + np.array(vs)**2)\n",
    "ms /= np.max(ms)\n",
    "ms = (ms * 255).astype(np.uint8)\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "out_path = 'output/flow_magnitude.gif'\n",
    "os.makedirs('output', exist_ok=True)\n",
    "imageio.mimsave(out_path, ms)\n",
    "Image(open(out_path, 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3UhZQgXMr43"
   },
   "source": [
    "We could also visualize the optical vector field directly, using `plt.quiver().` For clarity we will only display the first frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "4jk0Q7qZtdZz",
    "outputId": "08c4c78a-6e5d-4f9e-bd65-8573a3ed764d"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "x = np.arange(0, width, 1)\n",
    "y = np.arange(0, height, 1)\n",
    "x, y = np.meshgrid(x, y)\n",
    "step = 10\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.quiver(\n",
    "    x[::step, ::step], y[::step, ::step],\n",
    "    us[i][::step, ::step], vs[i][::step, ::step],\n",
    "    color='r', pivot='middle', headwidth=2, headlength=3)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Answers (Week 9) Optical Flow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
