{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5c6b2-2207-4f2d-8abe-3b4cc2cf1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114272a8-7c73-40d6-b130-fad1ae13605f",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b4b1c-1cf1-4d3a-a75b-79a0fedb1b05",
   "metadata": {},
   "source": [
    "In the previous module we trained a very simple multi-layer perceptron on the MNIST dataset. The performance was OK but not that impressive as MNIST is not a very difficult dataset by today's standard (or even the standard of around 20 years ago). In this notebook we will reuse the same settings but train a convolutional neural network instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07bc9c-a089-4a2f-bbc3-1b6fe77b1f20",
   "metadata": {},
   "source": [
    "Load datasets and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca697d6d-2c0c-416a-98d8-d677a26ed7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d7418-4417-43e9-8cfd-07b5c04cf328",
   "metadata": {},
   "source": [
    "(10 points) Define and create a convolutional neural network. Train your model on the train split and test it on the test split. Feel free to try out different layers and architectures, experiment with different optimizers, or adjust any hyperparameters such as the learning rate, the number of epochs or the batch sizes.\n",
    "\n",
    "*In order to get full credit, your model should achieve at least 96% accuracy on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d9bef-0caa-42f4-b751-c30ae4c7f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    # TODO\n",
    "\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756912be-c721-4765-9185-a4abd35036c8",
   "metadata": {},
   "source": [
    "Define the training loop and the testing loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29af059-10e6-414d-80e4-ce3f3f2dbd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for i, (inp, label) in enumerate(dataloader):\n",
    "        inp, label = inp.to(device), label.to(device)\n",
    "        \n",
    "        pred = model(inp)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            loss, seen = loss.item(), (i+1) * len(inp)\n",
    "            print(f\"[{seen:>5d}/{size:>5d}] loss: {loss:>7f}\")\n",
    "\n",
    "            \n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inp, label in dataloader:\n",
    "            inp, label = inp.to(device), label.to(device)\n",
    "            pred = model(inp)\n",
    "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test accuracy: {accuracy*100:>6.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ad97d-e8ca-4bb7-a979-9b8bb3dee63d",
   "metadata": {},
   "source": [
    "Run training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b8068-d6df-46be-ace6-2416b3814dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
